{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rSYt28dLgrCA",
        "outputId": "0dcd9aa3-e427-44d2-b5c0-334ce60f5a9a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Products Data Sample:\n",
            "      product_id product_description department_key   class_key  \\\n",
            "0  Product_10000          975G Pâtes  Department_10  Class_1050   \n",
            "1  Product_10001          891G Pâtes  Department_25  Class_2570   \n",
            "2  Product_10002          165G Pâtes  Department_10  Class_1050   \n",
            "3  Product_10003          861G Pâtes  Department_10  Class_1050   \n",
            "4  Product_10004         966G Savons  Department_31  Class_3124   \n",
            "\n",
            "     subclass_key sector brand_key   shelf_level1 shelf_level2  \\\n",
            "0  SubClass_10002    PGC   Brand_B  Department_10   Class_1050   \n",
            "1  SubClass_10004    PGC   Brand_A  Department_25   Class_2570   \n",
            "2  SubClass_10004    PGC   Brand_D  Department_10   Class_1050   \n",
            "3  SubClass_10004    PGC   Brand_D  Department_10   Class_1050   \n",
            "4  SubClass_10003    PGC   Brand_C  Department_31   Class_3124   \n",
            "\n",
            "     shelf_level3 shelf_level4  bio  sugar_free  gluten_free  vegan  \\\n",
            "0  SubClass_10002         None    0           1            0      1   \n",
            "1  SubClass_10004         None    0           1            0      0   \n",
            "2  SubClass_10004         None    1           1            0      1   \n",
            "3  SubClass_10004         None    0           1            0      1   \n",
            "4  SubClass_10003         None    1           0            1      0   \n",
            "\n",
            "   lactose_free  carrefour_brand  \n",
            "0             0                1  \n",
            "1             1                0  \n",
            "2             1                1  \n",
            "3             1                1  \n",
            "4             0                0  \n",
            "\n",
            "Train Data Sample:\n",
            "         date      transaction_id    customer_id     product_id  \\\n",
            "0  2022-11-25  Transaction_891301  Household_129  Product_10006   \n",
            "1  2023-09-09  Transaction_515155  Household_497  Product_10042   \n",
            "2  2023-08-09  Transaction_290722  Household_121  Product_10034   \n",
            "3  2023-12-18  Transaction_966362   Household_92  Product_10000   \n",
            "4  2022-10-03  Transaction_979436  Household_371  Product_10040   \n",
            "\n",
            "   has_loyalty_card store_id  is_promo  quantity    format order_channel  \n",
            "0                 0  Store_7         0         5     DRIVE      IN_STORE  \n",
            "1                 1  Store_9         1         4    PICKUP    MOBILE_APP  \n",
            "2                 0  Store_3         0         3  DELIVERY    MOBILE_APP  \n",
            "3                 0  Store_3         0         1  DELIVERY    MOBILE_APP  \n",
            "4                 1  Store_5         1         3    PICKUP      IN_STORE  \n",
            "\n",
            "Test Data Sample:\n",
            "       transaction_id    customer_id     product_id\n",
            "0  Transaction_437689  Household_192  Product_10037\n",
            "1  Transaction_573210   Household_70  Product_10001\n",
            "2  Transaction_177428   Household_26  Product_10039\n",
            "3  Transaction_714237  Household_178  Product_10003\n",
            "4  Transaction_636391  Household_359  Product_10034\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "# --- Étape 1 : Création de products_data ---\n",
        "num_products = 50\n",
        "products_data = []\n",
        "\n",
        "departments = [\"Department_25\", \"Department_31\", \"Department_10\"]\n",
        "classes = {\"Department_25\": [\"Class_2570\", \"Class_2571\"], \"Department_31\": [\"Class_3123\", \"Class_3124\"], \"Department_10\": [\"Class_1050\"]}\n",
        "subclasses = {cls: [f\"SubClass_{i}\" for i in range(10000, 10005)] for cls in sum(classes.values(), [])}\n",
        "brands = [\"Brand_A\", \"Brand_B\", \"Brand_C\", \"Brand_D\"]\n",
        "\n",
        "for i in range(num_products):\n",
        "    department = random.choice(departments)\n",
        "    class_key = random.choice(classes[department])\n",
        "    subclass_key = random.choice(subclasses[class_key])\n",
        "    brand = random.choice(brands)\n",
        "    product_id = f\"Product_{10000 + i}\"\n",
        "    description = f\"{random.randint(100, 1000)}G {random.choice(['Biscuits', 'Pâtes', 'Savons'])}\"\n",
        "    products_data.append({\n",
        "        \"product_id\": product_id,\n",
        "        \"product_description\": description,\n",
        "        \"department_key\": department,\n",
        "        \"class_key\": class_key,\n",
        "        \"subclass_key\": subclass_key,\n",
        "        \"sector\": \"PGC\",\n",
        "        \"brand_key\": brand,\n",
        "        \"shelf_level1\": department,\n",
        "        \"shelf_level2\": class_key,\n",
        "        \"shelf_level3\": subclass_key,\n",
        "        \"shelf_level4\": None,\n",
        "        \"bio\": random.choice([0, 1]),\n",
        "        \"sugar_free\": random.choice([0, 1]),\n",
        "        \"gluten_free\": random.choice([0, 1]),\n",
        "        \"vegan\": random.choice([0, 1]),\n",
        "        \"lactose_free\": random.choice([0, 1]),\n",
        "        \"carrefour_brand\": random.choice([0, 1])\n",
        "    })\n",
        "\n",
        "products_data = pd.DataFrame(products_data)\n",
        "\n",
        "# --- Étape 2 : Création des préférences clients ---\n",
        "n_customers = 500\n",
        "customer_ids = [f\"Household_{i}\" for i in range(1, n_customers + 1)]\n",
        "\n",
        "# Associer des clients à leurs produits préférés\n",
        "customer_preferences = {\n",
        "    customer: random.sample(products_data['product_id'].tolist(), random.randint(5, 10)) for customer in customer_ids\n",
        "}\n",
        "\n",
        "# --- Étape 3 : Générer train_data ---\n",
        "n_train = 10000\n",
        "start_date = pd.to_datetime(\"2022-01-01\")\n",
        "end_date = pd.to_datetime(\"2023-12-31\")\n",
        "\n",
        "train_data = []\n",
        "for _ in range(n_train):\n",
        "    customer_id = random.choice(customer_ids)\n",
        "    product_id = random.choice(customer_preferences[customer_id])\n",
        "    date = pd.to_datetime(np.random.randint(start_date.value, end_date.value), unit='ns')\n",
        "    train_data.append({\n",
        "        \"date\": date.strftime('%Y-%m-%d'),\n",
        "        \"transaction_id\": f\"Transaction_{random.randint(1, 1000000)}\",\n",
        "        \"customer_id\": customer_id,\n",
        "        \"product_id\": product_id,\n",
        "        \"has_loyalty_card\": random.choice([0, 1]),\n",
        "        \"store_id\": f\"Store_{random.randint(1, 10)}\",\n",
        "        \"is_promo\": random.choice([0, 1]),\n",
        "        \"quantity\": random.randint(1, 5),\n",
        "        \"format\": random.choice([\"DRIVE\", \"DELIVERY\", \"PICKUP\"]),\n",
        "        \"order_channel\": random.choice([\"MOBILE_APP\", \"WEBSITE\", \"IN_STORE\"])\n",
        "    })\n",
        "\n",
        "train_data = pd.DataFrame(train_data)\n",
        "\n",
        "# --- Étape 4 : Générer test_data basé sur train_data ---\n",
        "n_test = 2000\n",
        "test_data = []\n",
        "\n",
        "for _ in range(n_test):\n",
        "    customer_id = random.choice(customer_ids)\n",
        "    if random.random() < 0.8:\n",
        "        product_id = random.choice(customer_preferences[customer_id])\n",
        "    else:\n",
        "        product_id = random.choice(products_data['product_id'].tolist())\n",
        "    test_data.append({\n",
        "        \"transaction_id\": f\"Transaction_{random.randint(1, 1000000)}\",\n",
        "        \"customer_id\": customer_id,\n",
        "        \"product_id\": product_id\n",
        "    })\n",
        "\n",
        "test_data = pd.DataFrame(test_data)\n",
        "\n",
        "# --- Validation ---\n",
        "print(\"Products Data Sample:\")\n",
        "print(products_data.head())\n",
        "print(\"\\nTrain Data Sample:\")\n",
        "print(train_data.head())\n",
        "print(\"\\nTest Data Sample:\")\n",
        "print(test_data.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pOpL7G4VmXde",
        "outputId": "b5696941-ba2e-4a9a-ea35-a39882eece17"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.6.0)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install scikit-learn --upgrade"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AcPMS0DJmM7E",
        "outputId": "906d9813-1d69-4bcc-dcee-70f5a367277f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dimensions de X_train : (10000, 10471)\n",
            "Dimensions de y_train : (10000, 50)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "\n",
        "# Séparer X et y\n",
        "X = train_data.drop(columns=[\"product_id\"])  # Toutes les colonnes sauf product_id\n",
        "y = train_data[\"product_id\"]  # La cible (product_id)\n",
        "\n",
        "# Encodage de la variable cible (product_id)\n",
        "product_encoder = LabelEncoder()\n",
        "y_encoded = product_encoder.fit_transform(y)\n",
        "\n",
        "# Encodage des colonnes catégorielles dans X\n",
        "categorical_columns = X.select_dtypes(include=[\"object\"]).columns\n",
        "\n",
        "# Appliquer OneHotEncoder sur les colonnes catégorielles\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "encoder = OneHotEncoder(sparse_output=False, handle_unknown=\"ignore\") # sparse was deprecated in 1.2 and replaced with sparse_output\n",
        "X_encoded = pd.DataFrame(encoder.fit_transform(X[categorical_columns]))\n",
        "\n",
        "# Ajouter les colonnes numériques\n",
        "numerical_columns = X.select_dtypes(exclude=[\"object\"]).columns\n",
        "X_encoded = X_encoded.astype(np.float32)\n",
        "\n",
        "# Conversion en matrices numpy\n",
        "X_train = X_encoded.to_numpy()\n",
        "y_train = to_categorical(y_encoded, num_classes=len(product_encoder.classes_))\n",
        "\n",
        "print(f\"Dimensions de X_train : {X_train.shape}\")\n",
        "print(f\"Dimensions de y_train : {y_train.shape}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JU49ZL_wmkhL"
      },
      "outputs": [],
      "source": [
        "# Encodage des données de test\n",
        "X_test = test_data[['transaction_id', 'customer_id']]  # Select only the columns present in test_data and used for training\n",
        "\n",
        "# Get categorical columns present in both train and test data\n",
        "categorical_columns_test = list(set(categorical_columns) & set(X_test.columns))\n",
        "\n",
        "# Create missing columns in X_test and fill with a placeholder value (e.g., 0)\n",
        "# We fill with 0 because the numerical columns are related to the training data and do not exist in the test data.\n",
        "# Instead of 'missing', we use 0 to represent the absence of these features in the test data.\n",
        "for col in numerical_columns:\n",
        "    if col not in X_test.columns:\n",
        "        X_test[col] = 0\n",
        "\n",
        "# Create missing columns in X_test and fill with a placeholder value (e.g., 'missing')\n",
        "for col in categorical_columns:\n",
        "    if col not in X_test.columns:\n",
        "        X_test[col] = 'missing'  # Or any other suitable placeholder\n",
        "\n",
        "# Now you can safely apply the transform\n",
        "X_test_encoded = pd.DataFrame(encoder.transform(X_test[categorical_columns]))\n",
        "\n",
        "# Continue with the rest of your code...\n",
        "x_test_final = pd.concat([X_test_encoded, X_test[numerical_columns].reset_index(drop=True)], axis=1)\n",
        "X_test_final = x_test_final.to_numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VzA5KehOnO0u",
        "outputId": "11dec64f-7fec-4d7a-d69d-ae0a73dc4445"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 20ms/step - accuracy: 0.0262 - loss: 3.9030\n",
            "Epoch 2/10\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 24ms/step - accuracy: 0.1852 - loss: 3.5014\n",
            "Epoch 3/10\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 20ms/step - accuracy: 0.5897 - loss: 1.9796\n",
            "Epoch 4/10\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 23ms/step - accuracy: 0.9554 - loss: 0.5621\n",
            "Epoch 5/10\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.9995 - loss: 0.1034\n",
            "Epoch 6/10\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 0.0366\n",
            "Epoch 7/10\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0198\n",
            "Epoch 8/10\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 0.0125\n",
            "Epoch 9/10\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - accuracy: 1.0000 - loss: 0.0085\n",
            "Epoch 10/10\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 0.0061\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x794eb0b0dd20>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "num_features = X_train.shape[1]  # Nombre de colonnes dans X\n",
        "num_products = y_train.shape[1]  # Nombre de classes (produits)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(128, input_dim=num_features, activation=\"relu\"))\n",
        "model.add(Dense(64, activation=\"relu\"))\n",
        "model.add(Dense(num_products, activation=\"softmax\"))  # Prédictions des produits\n",
        "\n",
        "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "# Entraîner le modèle\n",
        "model.fit(X_train, y_train, epochs=10, batch_size=32)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YTT2nArFnQ1F"
      },
      "outputs": [],
      "source": [
        "def predict_product(model, top_n=10):\n",
        "    \"\"\"\n",
        "    Génère les produits recommandés pour chaque instance dans X_train.\n",
        "\n",
        "    Args:\n",
        "        model: Le modèle entraîné.\n",
        "        top_n: Le nombre de produits recommandés (par défaut : 10).\n",
        "\n",
        "    Returns:\n",
        "        Une liste de produits recommandés pour chaque exemple d'entraînement.\n",
        "    \"\"\"\n",
        "    # Prédire les probabilités pour les données d'entraînement\n",
        "    prediction = model.predict(X_train)\n",
        "\n",
        "    # Obtenir les indices des produits les plus probables\n",
        "    top_products = np.argsort(prediction, axis=1)[:, -top_n:][:, ::-1]\n",
        "\n",
        "    # Décoder les produits pour retourner les identifiants originaux\n",
        "    return [product_encoder.inverse_transform(top_products[i]) for i in range(len(top_products))]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cGrxxjOEvbyk",
        "outputId": "cd4b6447-1285-4ea2-8dd2-481093de7b27"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n"
          ]
        }
      ],
      "source": [
        "# Générer les recommandations\n",
        "predicted_products = predict_product(model)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VnLUR1ssnbZ1",
        "outputId": "f8b4c758-221b-4174-db04-68b620acd43b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hitrate@10 : 0.21\n"
          ]
        }
      ],
      "source": [
        "def hitrate_at_k(test_data, predicted_products, k=10):\n",
        "    \"\"\"\n",
        "    Calcule le Hitrate@K.\n",
        "\n",
        "    Args:\n",
        "        test_data: Le jeu de données de test contenant les produits réellement achetés.\n",
        "        predicted_products: Liste des produits recommandés par le modèle.\n",
        "        k: Le nombre de recommandations à considérer (par défaut : 10).\n",
        "\n",
        "    Returns:\n",
        "        Le score Hitrate@K.\n",
        "    \"\"\"\n",
        "    hits = 0\n",
        "\n",
        "    for i, true_product in enumerate(test_data[\"product_id\"]):\n",
        "        if true_product in predicted_products[i][:k]:  # Vérifier si le vrai produit est dans les top K recommandations\n",
        "            hits += 1\n",
        "\n",
        "    return hits / len(test_data)\n",
        "\n",
        "\n",
        "# Calcul du Hitrate@10\n",
        "hitrate = hitrate_at_k(test_data, predicted_products, k=10)\n",
        "print(f\"Hitrate@10 : {hitrate:.2f}\")\n"
      ]
    }
  ]
}